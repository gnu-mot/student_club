{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"빅데이터동아리_특강_20220523.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyOiPVIMJMV8z4hXJJ2pARGv"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# **2022년 빅데이터 동아리 특강 - 토픽 모델링 (2022년 5월 23일)**\n","\n","대학원 기술경영학과 (Management of Technology) - 송지훈 교수"],"metadata":{"id":"DxeO851fPQfw"}},{"cell_type":"markdown","source":["🧑👩 학생 여러분, 빅데이터 동아리에 오신걸 환영합니다 !\\\n","짧은 시간이지만, 여러분들이 다양한 특강을 기반으로 **스스로 학습** 및 **경진대회**에 **참가** 할 수 있는 **역량**을 갖출 수 있도록 지원하는게 주 목적 입니다."],"metadata":{"id":"2vldBTKF3JO4"}},{"cell_type":"markdown","source":["**나중을 위한 팁**\\\n","✅ You can only learn data science by doing data science. (실제로 코드를 구현해 봐야 합니다 ~) \\\n","✅ Practice, practice, practice. (연습하고 또 연습하세요, 이번 짧은 강의에서는 모든 세세한 내용을 전부 다룰수 없습니다 ~)\\\n","✅ Free resources everywhere. (인터넷상에는 무료로 데이터 분석 또는 프로그래밍 관련 공부를 할 수 있는 많은 자료들이 존재 합니다. 적극적으로 찾아서 이용하세요 ~)"],"metadata":{"id":"Y0o2Hs__rZcY"}},{"cell_type":"markdown","source":["# **한글처리를 위한 기본 세팅**"],"metadata":{"id":"RSkvpFnlQWu0"}},{"cell_type":"code","source":["!apt -qq -y install fonts-nanum"],"metadata":{"id":"cVTkc_DFIG8E"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.font_manager as fm\n","import matplotlib.pyplot as plt\n","sys_font=fm.findSystemFonts()\n","nanum_font = [f for f in sys_font if 'Nanum' in f]\n","print(f\"nanum_font number: {len(nanum_font)}\")\n","print(nanum_font)"],"metadata":{"id":"cIK2UFSlQZtp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["path = '/usr/share/fonts/truetype/nanum/NanumBarunGothic.ttf' \n","font_name = fm.FontProperties(fname=path, size=10).get_name()\n","print(font_name)\n","plt.rc('font', family=font_name)\n","fm._rebuild()"],"metadata":{"id":"dI9tXjWSQdWU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ======= 형태소 분석을 위해 한글 분석 모듈 konlpy를 설치한다. =============\n","!python -m pip install konlpy\n","import konlpy \n","print('KoNLPy version...:', konlpy.__version__)"],"metadata":{"id":"QzJDwRk8Qep1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 맞춤법을 고치기 위한 라이브러리 설치\n","# 코드를 실행 후 재시작 필요\n","!pip install git+https://github.com/ssut/py-hanspell.git "],"metadata":{"id":"hY5efw3fX5kE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Mecab이 필요한 경우에만 사용\n","# !bash <(curl -s https://raw.githubusercontent.com/konlpy/konlpy/master/scripts/mecab.sh)"],"metadata":{"id":"w6vBUUaeQshh"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **데이터 크롤링 부분 (구글 플레이 스토어)**"],"metadata":{"id":"WRhUzEj1FH95"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"8mguVGorW2xv"},"outputs":[],"source":["!pip install selenium # 셀레니움\n","!apt-get update \n","!apt install chromium-chromedriver"]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","from bs4 import BeautifulSoup\n","import random\n","import time"],"metadata":{"id":"kQZ2yK1jSXrD"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["약간의 문제가 있는 코드, 로컬 개발 환경에서는 정상 작동."],"metadata":{"id":"4oP3meU9en29"}},{"cell_type":"code","source":["# ---- 셀레니움 각종 함수들 불러오기\n","from selenium import webdriver\n","from selenium.webdriver.support.ui import WebDriverWait\n","from selenium.webdriver.support import expected_conditions as EC\n","from selenium.webdriver.common.keys import Keys\n","from selenium.webdriver.common.action_chains import ActionChains\n","from selenium.webdriver.common.by import By\n","\n","# ---- 옵션 설정 \n","chrome_options = webdriver.ChromeOptions()\n","chrome_options.add_argument('--headless')\n","chrome_options.add_argument('--no-sandbox') # \n","chrome_options.add_argument('--disable-dev-shm-usage')\n","\n","# ----- 웹드라이버 로딩\n","driver = webdriver.Chrome('chromedriver', options=chrome_options) # Colab 환경이 아닌 경우에는, chromedriver 파일을 컴퓨터에서 실행시켜야 함.\n","driver.maximize_window() # 크롬창 크기 최대\n","\n","# 드라이버가 해당 url 접속\n","url = 'https://play.google.com/store/apps/details?id=com.towneers.www&hl=ko&gl=US&showAllReviews=true' # \n","driver.get(url)\n","print(driver.title)\n","time.sleep(2)\n","SCROLL_PAUSE_TIME = 2\n","SCROLL_TIMES = 5 # \n","CLICK_PAUSE_TIME = 2\n","\n","# 리뷰 페이지의 마지막까지 스크롤 다운하기 위해 페이지의 높이를 return\n","last_height = driver.execute_script(\"return document.body.scrollHeight\")\n","\n","# 스크롤 가장 아래까지 내리기 ('더보기' 누르면서)\n","#while True:\n","for k in range(30):\n","    print(k)\n","    \n","    for i in range(SCROLL_TIMES): \n","        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n","        time.sleep(SCROLL_PAUSE_TIME) # 스크롤 다운 사이에 2초의 시간(pause)을 두어 에러를 방지\n","        print(\"내려감\")\n","    \n","    more_button = driver.find_elements(By.XPATH,\"//span[@class='RveJvd snByac']\")\n","    \n","    # '더 보기' 버튼이 있다면 눌러준다\n","    if more_button:\n","        more_button[0].click()\n","        print(\"clicked\")\n","    time.sleep(1)\n","    # 더이상 내려가는 곳이 없으면 break\n","    new_height = driver.execute_script(\"return document.body.scrollHeight\")\n","    print(new_height)\n","\n","    if new_height == last_height:\n","        print(last_height)\n","        break\n","\n","    last_height = new_height\n","    time.sleep(1)    "],"metadata":{"id":"SSkqtlaLS2du"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 총 리뷰 확인\n","reviews = driver.find_elements(By.XPATH,'//*[@jsname=\"fk8dgd\"]//div[@class=\"d15Mdf bAhLNe\"]')\n","print(f'총 {len(reviews)} 리뷰를 획득했다!')"],"metadata":{"id":"tjuZA9nNGYw2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 앱 이름\n","app_name = driver.find_element(By.CLASS_NAME, \"AHFaub\")\n","앱 = app_name.text\n","print(앱)\n","app_collector = [앱 for i in range(len(reviews))]\n","\n","# 유저 이름\n","user_name = driver.find_elements(By.XPATH, '//div[@class=\"bAhLNe kx8XBd\"]/span[@class=\"X43Kjb\"]') \n","print(f\"총 스크래핑한 유저의 수는: {len(user_name)}\") # (10번 loop)\n","name_collector = []\n","for name in user_name:\n","    name_collector.append(name.text)\n","    \n","# 리뷰 날짜\n","review_collector = []\n","for i in range(1,len(reviews)+1):\n","    review_date = driver.find_element(By.XPATH, f'//*[@id=\"fcxH9b\"]/div[4]/c-wiz/div/div[2]/div/div/main/div/div[1]/div[2]/div/div[{i}]/div/div[2]/div[1]/div[1]/div/span[2]') \n","    review_collector.append(review_date.text)\n","\n","# 평점 \n","score = driver.find_elements(By.XPATH,'//div[@class=\"pf5lIe\"]/div[@role=\"img\"]')\n","score_collector = []\n","for e in score:\n","    score_collector.append(e.get_attribute('aria-label').replace('별표 5개 만점에', '').replace('개를 받았습니다.', '').strip()) # first one is weird\n","    \n","final_score = score_collector[1:]\n","\n","# 좋아요 (리뷰가 도움이 되었는지에 대한 여부)\n","likes = driver.find_elements(By.XPATH,'//div[@class=\"jUL89d y92BAb\"]')\n","likes_collector =[]\n","for l in likes:\n","    likes_collector.append(l.text)\n","\n","# 리뷰 내용\n","review = driver.find_elements(By.XPATH,\"//span[@jsname='bN97Pc']\")\n","print(len(review))\n","review_content = []\n","for j in review:\n","    review_content.append(j.text)"],"metadata":{"id":"dhgruaTfNeD_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","df = pd.DataFrame(list(zip(app_collector,name_collector,review_collector, final_score,likes_collector,review_content)),\n","               columns =['앱이름','유저이름','리뷰날짜','평점','리뷰의 좋아요 개수','리뷰 내용'])\n","df    \n","\n","df.to_csv(\"당근리뷰.csv\", index=False, encoding=\"utf-8-sig\")  "],"metadata":{"id":"1umDLTf4dMgT"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **토픽 모델링 부분**"],"metadata":{"id":"0juml6yyFTf_"}},{"cell_type":"code","source":["import pandas as pd\n","df = pd.read_csv(\"https://raw.githubusercontent.com/gnu-mot/student_club/main/%EB%8B%B9%EA%B7%BC%EB%A6%AC%EB%B7%B0.csv\")\n","df.head()"],"metadata":{"id":"AXVSOJ-JFVhj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(f'총 {len(df)} 리뷰를 획득했다!')"],"metadata":{"id":"zjKMHAurMA2G"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.info()"],"metadata":{"id":"Y7Fi9ZNaH1Wb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 중복값 확인\n","duplicateRows = df[df['리뷰 내용'].duplicated()]\n","duplicateRows # 중복값은 없음"],"metadata":{"id":"Dehf1lZ5H2Tm"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## **텍스트 전처리**"],"metadata":{"id":"PMDbWf4SMHqj"}},{"cell_type":"code","source":["import re\n","def clean_text(text):  \n","    text = text.replace(\".\", \" \").strip()\n","    text = re.sub('[^가-힣|a-zA-Z]+', ' ', text) # 한국어, 영어를 제외하고 나머지를 필터링\n","    text = re.sub(' +', ' ', text)\n","    return text"],"metadata":{"id":"6KT_SQNAMRlO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df['전처리1'] = df['리뷰 내용'].apply(clean_text)"],"metadata":{"id":"1Lext_gqWhaC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.head()"],"metadata":{"id":"cwS1XibBWqAd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 맞춤법 교정\n","from hanspell import spell_checker\n","spelled_sent = spell_checker.check(df['전처리1'][1])\n","print(spelled_sent.checked) # 문법 교정 (주의: 너무 긴 문장의 경우, 정확도가 떨어지거나 제대로 작동하지 않음.)"],"metadata":{"id":"hBhN1Jz3Xv6K"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def spell_check(text):\n","    try:\n","        spelled_sent = spell_checker.check(text)\n","        text = spelled_sent.checked\n","    except:\n","        text = text\n","    return text"],"metadata":{"id":"Hg3zW7oVYK1S"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df['spell_check'] = df['전처리1'].apply(spell_check) # 15분 정도 소요 !! (시간을 절약하기 위해 아래 내용이 포함된 파일을 준비)"],"metadata":{"id":"ldHIbvTTYM86"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.head()"],"metadata":{"id":"rWplDemGZXTY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.to_csv(\"당근리뷰_맞춤법교정.csv\", index=False, encoding=\"utf-8-sig\")  "],"metadata":{"id":"ABHptrSHYwkg"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## **문서에서 명사만 추출**"],"metadata":{"id":"XETKmm4iW_Gx"}},{"cell_type":"code","source":["data = pd.read_csv(\"https://raw.githubusercontent.com/gnu-mot/student_club/main/%EB%8B%B9%EA%B7%BC%EB%A6%AC%EB%B7%B0_%EB%A7%9E%EC%B6%A4%EB%B2%95%EA%B5%90%EC%A0%95.csv\")\n","data['spell_check'] = data['spell_check'].str.strip()\n","data.head()"],"metadata":{"id":"6Wa4aZaFXvdU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 형태소 분석기 Okt 불러오기\n","from konlpy.tag import Okt\n","okt = Okt()"],"metadata":{"id":"YukHrcD4Wroc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from tqdm import tqdm"],"metadata":{"id":"JO5pPGqEa031"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["nouns = []\n","for i in tqdm(range(len(data))):\n","  nouns.append(okt.nouns(data['spell_check'][i]))  "],"metadata":{"id":"amzRDF13XjkA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(len(nouns))"],"metadata":{"id":"-LPBUkdUbDS6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(nouns[:2])"],"metadata":{"id":"R-vOwrEhbEE2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# custom한 방식으로 불용어 설정\n","stopwords = \"이 있 하 것 들 그 되 수 이 보 않 없 나 사람 주 아니 등 같 우리 때 년 가 한 지 대하 오 말 일 그렇 위하 저 전 난 일 걸 뭐 줄 만 건 분 개 끝 잼 이거 번 중 듯 때 게 내 말 나 수 거 점 것 의 가 이 은 들 는 좀 잘 걍 과 도 를 으로 자 에 와 한 하다 을 아 그\"\n","stopwords = list(set(stopwords.split(\" \")))\n","print(stopwords)"],"metadata":{"id":"OnmI_yf5bICi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["okt.nouns(\"나는 대학생이다\") # 리스트 형태로 저장 "],"metadata":{"id":"VUlbIfYWc8Qr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 다시 새롭게 추출 \n","nouns_new = []\n","for review in nouns:\n","  temp = []\n","  for element in review:\n","    if (element not in stopwords): # and len(element) > 1: # 불용어와 제거\n","      temp.append(element)\n","  nouns_new.append(temp)"],"metadata":{"id":"opbxDsJ4cqzr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(nouns_new[:2])"],"metadata":{"id":"CK22vv00dV4r"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## **gensim을 이용한 토픽 모델링 전처리**"],"metadata":{"id":"liUzmsJFef37"}},{"cell_type":"code","source":["texts = nouns_new.copy()"],"metadata":{"id":"KubPqqxBe8ZW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(texts[0])"],"metadata":{"id":"6i5nQ1aWfI5Y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from collections import Counter\n","nouns_counter = Counter(texts[0])\n","top_nouns = dict(nouns_counter.most_common(50))\n","top_nouns"],"metadata":{"id":"DLKszi-_fZ4Q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from gensim import corpora\n","kr_dictionary = corpora.Dictionary(nouns_new) # 단어들의 사전 만들기 (정수 인코딩)\n","print(kr_dictionary)\n","# 출현빈도가 적거나 자주 등장하는 단어는 제거 \n","kr_dictionary.filter_extremes(no_below=5, no_above=0.20)\n","\n","corpus = [kr_dictionary.doc2bow(text) for text in texts] # Term Document Frequency 만들기, 단어가 해당 문서에서 몇 번 출현하는지 여부\n","print(corpus[0]) # 수행된 결과에서 첫번째 뉴스 출력. 첫번째 문서의 인덱스는 0"],"metadata":{"id":"c80OXOQQdXq-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["의미: 인코딩이 1번으로된 단어는 해당 문서에서 4번 출현"],"metadata":{"id":"K-i_R8jLfPFc"}},{"cell_type":"code","source":["print(kr_dictionary)"],"metadata":{"id":"7pZ8OphAnuOO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(kr_dictionary[0], kr_dictionary[1], kr_dictionary[2])"],"metadata":{"id":"Vj6I66sif78C"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(corpus[1])"],"metadata":{"id":"t1Bpx-pUfE7Y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(kr_dictionary[5], kr_dictionary[11], kr_dictionary[18])"],"metadata":{"id":"cwhVrUWdfl0k"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data['spell_check'].iloc[0]"],"metadata":{"id":"coEi584_qy6y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data['spell_check'].iloc[1]"],"metadata":{"id":"2qet4WbrgDR8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 손쉽게 읽을 수 있는 형태로 변환\n","[[(kr_dictionary[id], freq) for id, freq in cp] for cp in corpus[:1]]"],"metadata":{"id":"R6Uu0am1jH2p"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## **토픽 모델 구축하기**"],"metadata":{"id":"6XpFpJQIjhGj"}},{"cell_type":"code","source":["import gensim"],"metadata":{"id":"oxfNBRZblhk9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["* num_topics : 가설로 정한 토픽의 갯수\n","* chunksize : 얼마나 많은 문서가 훈련 알고리즘에 사용되는지\n","(만약에 빠른 학습이 중요하다면, 청크사이즈를 증가)\n","그러나 Chunksize는 모델 품질에 영향을 미치칠 수 있음\n","* passes : 패스는 모델 학습시 전체 코퍼스에서 모델을 학습시키는 빈도를 제어\n","* iteration : 각각 문서에 대해서 루프를 얼마나 돌리는지를 제어\n","* alpha, eta = auto, 디리클레 분포에 대한 파라미터"],"metadata":{"id":"54J_txJJmNMR"}},{"cell_type":"markdown","source":["https://radimrehurek.com/gensim/models/ldamodel.html#gensim.models.ldamodel.LdaModel"],"metadata":{"id":"UKbwNKd1ld2i"}},{"cell_type":"code","source":["# LDA 모델 생성 - 대략 \n","lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus, \n","                                           num_topics = 10, \n","                                           id2word=kr_dictionary,\n","                                           random_state=2022,\n","                                           passes=5,\n","                                           iterations=50\n","                                           )"],"metadata":{"id":"KTBBzsMhpLm5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["topics = lda_model.print_topics(num_words=10)\n","for topic in topics:\n","    print(topic)"],"metadata":{"id":"k9ZrhmxjnW-t"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 나중에 더 자세히 다룰 내용\n","tm1 = lda_model[corpus[0]] # 첫 번째 문서에는 어떤 토픽이 ?\n","tm1"],"metadata":{"id":"shjl7eb8r1zv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tm2 = lda_model[corpus[1]] # 두 번째 문서에는 어떤 토픽이 ?\n","tm2"],"metadata":{"id":"v7-0UV9fsPSP"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## **토픽 모델 시각화하기 (I)**"],"metadata":{"id":"0mm9hA7WxKdp"}},{"cell_type":"code","source":["!pip install pyLDAvis==2.1.2 # colab에서는 최신 버전이 제대로 작동하지 않는 경우가 있음"],"metadata":{"id":"kCEeqyWJxZ0-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Plotting tools\n","import pyLDAvis\n","import pyLDAvis.gensim"],"metadata":{"id":"E664R_YFwK2T"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["vis = pyLDAvis.gensim.prepare(lda_model, corpus, kr_dictionary)\n","pyLDAvis.save_html(vis, 'result.html')"],"metadata":{"id":"u1oDrs64xM0V"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pyLDAvis.gensim as gensimvis\n","vis_data = gensimvis.prepare(lda_model, corpus, kr_dictionary, sort_topics=False)\n","pyLDAvis.display(vis_data)"],"metadata":{"id":"tDTpoyXu6cSj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**원의 크기:** 자주 출현하는 토픽일수록 원의 크기가 증가\n","\n","**근접한 원들:** 상대적으로 유사한 토픽을 의미 (멀리 떨어져 있을수록 다른 내용을 다루고 있는 토픽들)"],"metadata":{"id":"1x_egVhDZm9F"}},{"cell_type":"markdown","source":["**람다(λ)의 의미**\n","\n","* Values of lambda that are very close to zero will show terms that are more specific for a chosen topic. Meaning that you will see terms that are \"important\" for that specific topic but not necessarily \"important\" for the whole corpus. (해당 주제에 특화된 단어들을 표시)\n","\n","* Values of lambda that are very close to one will show those terms that have the highest ratio between frequency of the terms for that specific topic and the overall frequency of the terms from the corpus. (전체에서 많이 나오는 단어이며 동시에 해당 주제에서도 더 자주 출현하는 단어들)"],"metadata":{"id":"9sdyzo9LXmjU"}},{"cell_type":"markdown","source":["## **토픽 모델 시각화하기 (II)**"],"metadata":{"id":"s3gzDqVV7H78"}},{"cell_type":"code","source":["# for i, topic in enumerate(lda_model.get_topics()):\n","#   print(i)\n","#   print(topic)\n","#   print(len(topic))\n","#   break"],"metadata":{"id":"zSh4PFWJP5Uu"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jGScRRrA61os"},"outputs":[],"source":["n_words = 10\n","\n","topic_words = pd.DataFrame({})\n","\n","for i, topic in enumerate(lda_model.get_topics()):\n","    top_feature_ids = topic.argsort()[-n_words:][::-1]\n","    feature_values = topic[top_feature_ids]\n","    words = [kr_dictionary[id] for id in top_feature_ids]\n","    topic_df = pd.DataFrame({'value': feature_values, 'word': words, 'topic': i})\n","    topic_words = pd.concat([topic_words, topic_df], ignore_index=True)\n","\n","topic_words.head(10)"]},{"cell_type":"code","source":["import seaborn as sns\n","import matplotlib.pyplot as plt\n","g = sns.FacetGrid(topic_words, col=\"topic\", col_wrap=3, sharey=False)\n","g.map(plt.barh, \"word\", \"value\", color='lightgray',edgecolor =\"black\")"],"metadata":{"id":"Irr6YQ2fI4uQ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## **토픽 분포 보기**"],"metadata":{"id":"eCKl8j4Y2yW8"}},{"cell_type":"code","source":["print(corpus[0])"],"metadata":{"id":"PlMlNh5h4_L2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for i, topic_list in enumerate(lda_model[corpus]):\n","    if i==5:\n","        break\n","    print(i,'번째 문서의 topic 비율은',topic_list)"],"metadata":{"id":"IM7_wih921nA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["topic_table = pd.DataFrame()"],"metadata":{"id":"h6OB0uls5SXS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 각 문서에 대해서 비중이 높은 토픽순으로 토픽을 정렬한다.\n","for i, topic_list in enumerate(lda_model[corpus]):\n","  ## lda_model.per_word_topics가 True면 topic_list[0]을 fasle면 topic_list 전체를 할당\n","  doc = topic_list[0] if lda_model.per_word_topics else topic_list\n","  #print(doc)           \n","  doc = sorted(doc, key=lambda x: (x[1]), reverse=True)\n","  #print(doc)\n","  for j, (topic_num, prop_topic) in enumerate(doc): # 몇 번 토픽인지와 비중을 나눠서 저장\n","    if j == 0:\n","      ## 정렬을 한 상태이므로 가장 앞이 비중이 높음\n","      topic_table = topic_table.append(pd.Series([int(topic_num), round(prop_topic, 4), topic_list]), ignore_index = True)\n","    else:\n","      break"],"metadata":{"id":"ipbAhROiSn12"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["topic_table"],"metadata":{"id":"UeGc1RneWNLf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["topic_table = topic_table.reset_index()\n","topic_table.columns = ['문서 번호', '가장 비중이 높은 토픽', '가장 높은 토픽의 비중', '각 토픽의 비중']\n","topic_table[:10]"],"metadata":{"id":"KPXvnc_KSeeO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**성능을 개선하기 위해선?**\n","\n","* 명사 뿐만 아니라 형용사, 동사도 사용\n","* 모델에 집어넣기 전에 너무 자주 나오는 단어 필터링\n","* 최적의 토픽 개수 (Coherence Model)"],"metadata":{"id":"GXjRqDS9YP2r"}},{"cell_type":"code","source":["topic_modeling_results = lda_model[corpus]\n","results = list(topic_modeling_results)\n","print(results)"],"metadata":{"id":"WyeVkAAILvqT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["corpus_topics = [sorted(topics, key=lambda record: -record[1])[0] for topics in results]\n","print(corpus_topics) # 가장 dominant한 topic 만 추출해서 리스트로 저장\n","print(len(corpus_topics))"],"metadata":{"id":"N26OI7LNMQd0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["topics = [[(term, round(wt, 3)) for term, wt in lda_model.show_topic(n, topn=20)] for n in range(0, lda_model.num_topics)]\n","print(topics)"],"metadata":{"id":"eJIfC5Y6MerY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# topci-term matrix\n","topics_df = pd.DataFrame([[term for term, wt in topic] for topic in topics], columns = ['Term'+str(i) for i in range(1, 21)],\n","                         index=['Topic '+str(t) for t in range(1, lda_model.num_topics+1)]).T\n","topics_df.head(20)"],"metadata":{"id":"wdw-u-O_MpNl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["topics_df2 = pd.DataFrame([', '.join([term for term, wt in topic]) for topic in topics], columns = ['Terms per Topic'],\n","                         index=['Topic'+str(t) for t in range(1, lda_model.num_topics+1)] )\n","topics_df2"],"metadata":{"id":"R7PWp0pcM0hK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# create a dataframe \n","corpus_topic_df = pd.DataFrame()\n","\n","corpus_topic_df['Dominant Topic'] = [item[0] for item in corpus_topics]\n","corpus_topic_df['Contribution %'] = [round(item[1]*100, 2) for item in corpus_topics]\n","corpus_topic_df['Topic Terms'] = [topics_df2.iloc[t[0]]['Terms per Topic'] for t in corpus_topics]\n","\n","corpus_topic_df.head()"],"metadata":{"id":"oYnSlI3LNDp_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["len(corpus_topic_df)"],"metadata":{"id":"K28Y20dcNWHW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dominant_topic_df = corpus_topic_df.groupby('Dominant Topic').agg(\n","                                  Doc_Count = ('Dominant Topic', np.size),\n","                                  Total_Docs_Perc = ('Dominant Topic', np.size)).reset_index()\n","\n","dominant_topic_df['Total_Docs_Perc'] = dominant_topic_df['Total_Docs_Perc'].apply(lambda row: round((row*100) / len(corpus), 2))\n","\n","dominant_topic_df"],"metadata":{"id":"7mzDfYp6N7xV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## **토픽의 갯수 정하기 (== 토픽 모델 평가)**"],"metadata":{"id":"Hztyy7UMikam"}},{"cell_type":"markdown","source":["Coherence는 주제의 일관성을 측정.\\\n","토픽이 얼마나 의미적으로 일관성이 높으지 평가\\\n","토픽 모델이 모델링이 잘 되었을수록 한 주제 안에는 의미론적으로 유사한 단어가 모이게 됨.\\\n","상위 단어 간의 유사도를 계산하면 실제로 해당 주제가 의미론적으로 일치하는 단어들끼리 모여있는지 알 수 있음\n","\n","- 토픽이 얼마나 의미론적으로 일관성 있는지.\n","- 높을수록 의미론적 일관성 높음"],"metadata":{"id":"qUpnAGtZYb-Y"}},{"cell_type":"markdown","source":["Perplexity(혼란도)는 확률 모델이 실제 관측되는 값을 얼마나 잘 예측하는지를 평가\\\n","값이 작을수록 토픽 모델이 문서를 잘 반영 (최적의 토픽을 결정할 때 사용 -> 최소점) "],"metadata":{"id":"1mbccQitb0zS"}},{"cell_type":"code","source":["from gensim.models import CoherenceModel\n","coherence_model = CoherenceModel(model = lda_model, texts = texts, dictionary = kr_dictionary, coherence = 'c_v')"],"metadata":{"id":"ck_8OgRhgLNC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["coherence_model.get_coherence()"],"metadata":{"id":"AF4mlqQZZAXK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import warnings \n","warnings.filterwarnings('ignore')"],"metadata":{"id":"r1uKaQ6ladJ6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["coherence_values = []\n","perplexities=[] # 낮을 수록 더 좋은 값\n","model_list = []\n","for i in range(2,21):\n","  ldamodel = gensim.models.ldamodel.LdaModel(corpus, num_topics = i, id2word=kr_dictionary, passes=5,random_state=2022, iterations=50)\n","  model_list.append(ldamodel)\n","  coherencemodel = CoherenceModel(model=ldamodel, texts=texts, dictionary=kr_dictionary, coherence='c_v')\n","  coherence_values.append(coherencemodel.get_coherence())\n","  perplexities.append(ldamodel.log_perplexity(corpus))"],"metadata":{"id":"3nkKtJTkZAjM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["coherence_values"],"metadata":{"id":"7g3iVlxFbG4P"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["최적의 토픽은 18개"],"metadata":{"id":"qQHljOpbiuHr"}},{"cell_type":"code","source":["x = range(2, 21, 1)\n","plt.plot(x, coherence_values)\n","plt.xlabel(\"Num Topics\")\n","plt.ylabel(\"Coherence score\")\n","plt.legend((\"Coherence\"), loc='best')\n","plt.show()"],"metadata":{"id":"OwUIujdadLIh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["x = range(2, 21, 1)\n","plt.plot(x, perplexities)\n","plt.xlabel(\"Num Topics\")\n","plt.ylabel(\"Perplexity\")\n","plt.show()"],"metadata":{"id":"EyIlOPj4aYru"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model_list"],"metadata":{"id":"bY_I5E3Ke4dt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["topics = model_list[-3].print_topics(num_words=10)\n","for topic in topics:\n","    print(topic)"],"metadata":{"id":"XH5Hok0qbOGq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["vis = pyLDAvis.gensim.prepare(model_list[-3], corpus, kr_dictionary)\n","pyLDAvis.save_html(vis, 'result_better.html')"],"metadata":{"id":"eFPhew2ifJIq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## **새로운 문서의 토픽 할당**"],"metadata":{"id":"HCqjLvS8fk3K"}},{"cell_type":"code","source":["# 훈련에 사용된 corpus가 아닌 새로운 document에 대해 토픽 모델링을 수행할 수 있으나\n","# 정확도는 다소 떨어질 수 있다.\n","def doc_to_bow(doc): #\n","    token = okt.nouns(doc) # 명사만 추출\n","    temporary = []\n","    for t in token:\n","      if t not in stopwords:\n","        temporary.append(t)\n","    bow = kr_dictionary.doc2bow(temporary)\n","    return bow"],"metadata":{"id":"utnh9uQcfoUE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["result = model_list[-3][(doc_to_bow('업데이트가 느려서 불편해요'))]\n","print(result)"],"metadata":{"id":"DV7TMXeLiGwp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["result = model_list[-3][(doc_to_bow('미국 영국 독일'))] # 전혀 상관없는 문장의 경우,균등하게 나눈 토픽으로 판단\n","print(result)"],"metadata":{"id":"vu_Hbov-iWZw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"L38dc4tviO8A"},"execution_count":null,"outputs":[]}]}